{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "from numpy import asarray, save\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 64, 64, 3) (630,)\n"
     ]
    }
   ],
   "source": [
    "folder1 = 'Dataset/train/smiley/'\n",
    "folder2 = 'Dataset/train/frown/'\n",
    "photos, labels = list(),list()\n",
    "\n",
    "for file in listdir(folder1):\n",
    "    output=0.0\n",
    "    if (file.startswith('Smile') or file.startswith('aug_') ):\n",
    "        output =1.0\n",
    "    photo = load_img(folder1 + file, target_size=(64,64))\n",
    "    photo=img_to_array(photo)\n",
    "    \n",
    "    photos.append(photo)\n",
    "    labels.append(output)\n",
    "for file in listdir(folder2):\n",
    "    output=1.0\n",
    "    if (file.startswith('Frown') or file.startswith('aug_') ):\n",
    "        output =0.0\n",
    "    photo = load_img(folder2 + file, target_size=(64,64))\n",
    "    photo=img_to_array(photo)\n",
    "    \n",
    "    photos.append(photo)\n",
    "    labels.append(output)\n",
    "\n",
    "photos = asarray(photos)\n",
    "labels=asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "\n",
    "save('train_smiley_frown_photos.npy', photos)\n",
    "save('train_smiley_frown_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3) (10,)\n"
     ]
    }
   ],
   "source": [
    "folder1 = 'Dataset/valid/smiley/'\n",
    "folder2 = 'Dataset/valid/frown/'\n",
    "photos, labels = list(),list()\n",
    "\n",
    "for file in listdir(folder1):\n",
    "    output=0.0\n",
    "    if (file.startswith('Smile') or file.startswith('aug_') ):\n",
    "        output =1.0\n",
    "    photo = load_img(folder1 + file, target_size=(64,64))\n",
    "    photo=img_to_array(photo)\n",
    "    \n",
    "    photos.append(photo)\n",
    "    labels.append(output)\n",
    "for file in listdir(folder2):\n",
    "    output=1.0\n",
    "    if (file.startswith('Frown') or file.startswith('aug_') ):\n",
    "        output =0.0\n",
    "    photo = load_img(folder2 + file, target_size=(64,64))\n",
    "    photo=img_to_array(photo)\n",
    "    \n",
    "    photos.append(photo)\n",
    "    labels.append(output)\n",
    "\n",
    "photos = asarray(photos)\n",
    "labels=asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "\n",
    "save('test_smiley_frown_photos.npy', photos)\n",
    "save('test_smiley_frown_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load('train_smiley_frown_photos.npy')\n",
    "y_train = load('train_smiley_frown_labels.npy')\n",
    "x_test = load('test_smiley_frown_photos.npy')\n",
    "y_test = load('test_smiley_frown_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    " print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:,:,:,1]\n",
    "x_test = x_test[:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 64, 64) (10, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(630,64,64,1)\n",
    "x_test = x_test.reshape(10,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 64, 64, 1) (10, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "pl = x_train[0].reshape(64,64)\n",
    "plt.imshow(pl, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_train[7])\n",
    "from keras.optimizers import Adam\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,(3,3), activation='relu', input_shape=(64, 64, 1)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples, validate on 10 samples\n",
      "Epoch 1/5\n",
      "630/630 [==============================] - 4s 7ms/step - loss: 67.7682 - accuracy: 0.6175 - val_loss: 15.8480 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "630/630 [==============================] - 4s 7ms/step - loss: 4.5416 - accuracy: 0.8905 - val_loss: 2.5645 - val_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "630/630 [==============================] - 4s 6ms/step - loss: 0.1609 - accuracy: 0.9825 - val_loss: 1.0841 - val_accuracy: 0.9000\n",
      "Epoch 4/5\n",
      "630/630 [==============================] - 4s 6ms/step - loss: 0.0225 - accuracy: 0.9968 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "630/630 [==============================] - 4s 6ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.1786 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1a80329b80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,validation_data=(x_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "(64, 64)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Dataset/test/smiley/f2.png')\n",
    "print(img.shape)\n",
    "grey = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "print(grey.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(grey.reshape(1,64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(predictions.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Smiley_Recognition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
